{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install -q -U jax jaxlib flax","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-21T13:13:48.350345Z","iopub.execute_input":"2022-06-21T13:13:48.350648Z","iopub.status.idle":"2022-06-21T13:13:58.375297Z","shell.execute_reply.started":"2022-06-21T13:13:48.350568Z","shell.execute_reply":"2022-06-21T13:13:58.373766Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport requests\nfrom typing import Any\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom tqdm.autonotebook import tqdm\n\nimport jax\nimport flax\nimport optax\nfrom jax import lax\nimport flax.linen as nn\nfrom flax.training import train_state, common_utils\n\nimport numpy as np\nimport jax.numpy as jnp\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:13:58.379794Z","iopub.execute_input":"2022-06-21T13:13:58.380127Z","iopub.status.idle":"2022-06-21T13:14:03.418051Z","shell.execute_reply.started":"2022-06-21T13:13:58.380089Z","shell.execute_reply":"2022-06-21T13:14:03.416963Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  import sys\n2022-06-21 13:14:00.081029: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","output_type":"stream"}]},{"cell_type":"code","source":"if 'TPU_NAME' in os.environ:\n    if 'TPU_DRIVER_MODE' not in globals():\n        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n        resp = requests.post(url)\n        TPU_DRIVER_MODE = 1\n    from jax.config import config as jax_config\n    jax_config.FLAGS.jax_xla_backend = \"tpu_driver\"\n    jax_config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n    print(\"TPU DETECTED!\")\n    print('Registered TPU:', jax_config.FLAGS.jax_backend_target)\nelif \"COLAB_TPU_ADDR\" in os.environ:\n    import jax.tools.colab_tpu\n    jax.tools.colab_tpu.setup_tpu()\nelse:\n    print('No TPU detected.')\n\nDEVICE_COUNT = len(jax.local_devices())\nTPU = DEVICE_COUNT == 8\n\nDATA_PATH = \"../input/tpu-getting-started/tfrecords-jpeg-224x224\"\n\nif TPU:\n    print(\"8 cores of TPU ( Local devices in Jax ):\")\n    print('\\n'.join(map(str,jax.local_devices())))","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:14:03.419842Z","iopub.execute_input":"2022-06-21T13:14:03.420504Z","iopub.status.idle":"2022-06-21T13:14:22.045364Z","shell.execute_reply.started":"2022-06-21T13:14:03.420456Z","shell.execute_reply":"2022-06-21T13:14:22.044146Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"TPU DETECTED!\nRegistered TPU: grpc://10.0.0.2:8470\n8 cores of TPU ( Local devices in Jax ):\nTPU_0(host=0,(0,0,0,0))\nTPU_1(host=0,(0,0,0,1))\nTPU_2(host=0,(1,0,0,0))\nTPU_3(host=0,(1,0,0,1))\nTPU_4(host=0,(0,1,0,0))\nTPU_5(host=0,(0,1,0,1))\nTPU_6(host=0,(1,1,0,0))\nTPU_7(host=0,(1,1,0,1))\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 0\nLATENT_DIM = 128\nIMAGE_SIZE = 32\nBATCH_SIZE = 64\nDEVICE_BATCH_SIZE = DEVICE_COUNT * BATCH_SIZE\nEPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:14:22.048052Z","iopub.execute_input":"2022-06-21T13:14:22.048890Z","iopub.status.idle":"2022-06-21T13:14:22.054397Z","shell.execute_reply.started":"2022-06-21T13:14:22.048840Z","shell.execute_reply":"2022-06-21T13:14:22.053617Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(sample):\n    sample = tf.image.convert_image_dtype(sample['image'], tf.float32)\n    sample = sample / 255. * 2. - 1.\n    return sample\n\n\ntrain_dataset = tfds.load(\"cifar10\")['train']\ntrain_size = len(train_dataset)\n\ntrain_dataset = train_dataset.map(\n    preprocess_data, num_parallel_calls=tf.data.AUTOTUNE\n)\ntrain_dataset = train_dataset.cache()\ntrain_dataset = train_dataset.repeat()\ntrain_dataset = train_dataset.batch(DEVICE_BATCH_SIZE)\n\ndata_generator = iter(tfds.as_numpy(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:14:22.057055Z","iopub.execute_input":"2022-06-21T13:14:22.058131Z","iopub.status.idle":"2022-06-21T13:14:22.361339Z","shell.execute_reply.started":"2022-06-21T13:14:22.058057Z","shell.execute_reply":"2022-06-21T13:14:22.360121Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2022-06-21 13:14:22.088178: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-06-21 13:14:22.088263: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    c_hid : int\n    latent_dim : int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(features=self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 32x32 => 16x16\n        x = nn.gelu(x)\n        x = nn.Conv(features=self.c_hid, kernel_size=(3, 3))(x)\n        x = nn.gelu(x)\n        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 16x16 => 8x8\n        x = nn.gelu(x)\n        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3))(x)\n        x = nn.gelu(x)\n        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 8x8 => 4x4\n        x = nn.gelu(x)\n        x = x.reshape(x.shape[0], -1)  # Image grid to single feature vector\n        x = nn.Dense(features=self.latent_dim)(x)\n        return x\n\n\nclass Decoder(nn.Module):\n    c_out : int\n    c_hid : int\n    latent_dim : int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(features=2*16*self.c_hid)(x)\n        x = nn.gelu(x)\n        x = x.reshape(x.shape[0], 4, 4, -1)\n        x = nn.ConvTranspose(features=2*self.c_hid, kernel_size=(3, 3), strides=(2, 2))(x)\n        x = nn.gelu(x)\n        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3))(x)\n        x = nn.gelu(x)\n        x = nn.ConvTranspose(features=self.c_hid, kernel_size=(3, 3), strides=(2, 2))(x)\n        x = nn.gelu(x)\n        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3))(x)\n        x = nn.gelu(x)\n        x = nn.ConvTranspose(features=self.c_out, kernel_size=(3, 3), strides=(2, 2))(x)\n        x = nn.tanh(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:14:22.363473Z","iopub.execute_input":"2022-06-21T13:14:22.363857Z","iopub.status.idle":"2022-06-21T13:14:22.391697Z","shell.execute_reply.started":"2022-06-21T13:14:22.363812Z","shell.execute_reply":"2022-06-21T13:14:22.390431Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    c_hid: int\n    latent_dim : int\n\n    def setup(self):\n        # Alternative to @nn.compact -> explicitly define modules\n        # Better for later when we want to access the encoder and decoder explicitly\n        self.encoder = Encoder(c_hid=self.c_hid, latent_dim=self.latent_dim)\n        self.decoder = Decoder(c_hid=self.c_hid, latent_dim=self.latent_dim, c_out=3)\n\n    def __call__(self, x):\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        return x_hat","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:14:22.393623Z","iopub.execute_input":"2022-06-21T13:14:22.393977Z","iopub.status.idle":"2022-06-21T13:14:22.409624Z","shell.execute_reply.started":"2022-06-21T13:14:22.393931Z","shell.execute_reply":"2022-06-21T13:14:22.407986Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"@partial(jax.pmap, static_broadcasted_argnums=(1))\ndef initialize_autoencoder_state(key, input_shape):\n    model = Autoencoder(c_hid=32, latent_dim=128)\n    variables = model.init(key, jnp.ones(input_shape))\n    tx = optax.chain(\n        optax.clip(1.0),\n        optax.adam(\n            optax.warmup_cosine_decay_schedule(\n                init_value=0.0,\n                peak_value=1e-3,\n                warmup_steps=100,\n                decay_steps=EPOCHS * train_size,\n                end_value=1e-5\n            )\n        )\n    )\n    return train_state.TrainState.create(\n        apply_fn=model.apply,\n        tx=tx,\n        params=variables['params']\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(seed=SEED)\nautoencoder_key, key = jax.random.split(key, 2)\nautoencoder_key = common_utils.shard_prng_key(autoencoder_key)\nautoencoder_state = initialize_autoencoder_state(\n    autoencoder_key, (BATCH_SIZE, *next(data_generator).shape[1:])\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:29:08.188868Z","iopub.execute_input":"2022-06-21T13:29:08.189390Z","iopub.status.idle":"2022-06-21T13:29:08.200492Z","shell.execute_reply.started":"2022-06-21T13:29:08.189335Z","shell.execute_reply":"2022-06-21T13:29:08.199360Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"@partial(jax.pmap, axis_name='num_devices')\ndef train_step(state: train_state.TrainState, image_batch: jnp.ndarray, key: jnp.ndarray):\n    \n    def loss_fn(params):\n        reconstructed_images = state.apply_fn({'params': params}, image_batch)\n        loss = ((reconstructed_images - image_batch) ** 2).mean(axis=0).sum()\n        return loss, reconstructed_images\n    \n    gradient_fn = jax.value_and_grad(loss_fn, has_aux=True)\n    (loss, reconstructed_images), gradients = gradient_fn(state.params)\n    gradients = jax.lax.pmean(gradients, axis_name='num_devices')\n    loss = jax.lax.pmean(loss, axis_name='num_devices')\n    updated_state = state.apply_gradients(grads=gradients)\n    return updated_state, loss","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:31:07.537274Z","iopub.execute_input":"2022-06-21T13:31:07.537912Z","iopub.status.idle":"2022-06-21T13:31:19.045240Z","shell.execute_reply.started":"2022-06-21T13:31:07.537859Z","shell.execute_reply":"2022-06-21T13:31:19.042984Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train(data_generator, epochs: int, batches_in_epoch: int, state: train_state.TrainState, key: jnp.ndarray):\n    for epoch in tqdm(range(1, epochs + 1), desc=\"Epoch\", position=0, leave=True):\n        with tqdm(total=batches_in_epoch, desc=\"Training\", leave=False) as progress_bar:\n            key, autoencoder_key = jax.random.split(key, 2)\n            autoencoder_key = common_utils.shard_prng_key(autoencoder_key)\n            batch_data = common_utils.shard(next(data_generator))\n            updated_state, loss = train_step(state, batch_data, key)\n            progress_bar.update(1)\n        metrics = jax.device_get([loss])\n        progress_bar.write(f\"Epoch: {epoch: <2} | Loss: {metrics[0]:.3f}\")\n    return state","metadata":{},"execution_count":null,"outputs":[]}]}